{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@kconsidder You never tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Sick today  coding from the couch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@ChargerJenn Thx for answering so quick,I was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Wii fit says I've lost 10 pounds since last ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@MrKinetik Not a thing!!!  I don't really have...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                               text\n",
       "0         0                      @kconsidder You never tweet  \n",
       "1         0                 Sick today  coding from the couch.\n",
       "2         1  @ChargerJenn Thx for answering so quick,I was ...\n",
       "3         1  Wii fit says I've lost 10 pounds since last ti...\n",
       "4         0  @MrKinetik Not a thing!!!  I don't really have..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/sentiment140-subset.csv\", nrows=30000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DfFittedVectorizer.sav']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "vectors = vectorizer.fit_transform(df.text)\n",
    "words_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
    "words_df.head()\n",
    "joblib.dump(vectorizer, 'trained_models/DfFittedVectorizer.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = words_df\n",
    "y = df.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.3 s, sys: 3.53 s, total: 36.8 s\n",
      "Wall time: 11.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000000.0, max_iter=1000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a logistic regression\n",
    "logreg = LogisticRegression(C=1e9, solver='lbfgs', max_iter=1000)\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_models/LogRegForSentimentAnalysis.sav']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export trained model\n",
    "joblib.dump(logreg, \"trained_models/LogRegForSentimentAnalysis.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 516 ms, sys: 178 ms, total: 694 ms\n",
      "Wall time: 374 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a multinomial naive bayes classifier (MultinomialNB)\n",
    "bayes = MultinomialNB()\n",
    "bayes.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_models/NaiBayesForSentimentAnalysis.sav']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export trained model\n",
    "joblib.dump(bayes, \"trained_models/NaiBayesForSentimentAnalysis.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I dont know what to think about it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That was fucking awesome dawg!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goddamn what a miracle!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Son of a bitch!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              content\n",
       "0  I dont know what to think about it\n",
       "1      That was fucking awesome dawg!\n",
       "2             Goddamn what a miracle!\n",
       "3                     Son of a bitch!"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create some test data\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "unknown = pd.DataFrame({'content': [\n",
    "    \"I dont know what to think about it\",\n",
    "    \"That was fucking awesome dawg!\",\n",
    "    \"Goddamn what a miracle!\",\n",
    "    \"Son of a bitch!\"\n",
    "]})\n",
    "unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '100', '11', '12', '15', '1st', '20', '2day', '2nd', '30', 'able', 'about', 'account', 'actually', 'add', 'after', 'afternoon', 'again', 'ago', 'agree', 'ah', 'ahh', 'ahhh', 'air', 'album', 'all', 'almost', 'alone', 'already', 'alright', 'also', 'although', 'always', 'am', 'amazing', 'amp', 'an', 'and', 'annoying', 'another', 'any', 'anymore', 'anyone', 'anything', 'anyway', 'app', 'apparently', 'apple', 'appreciate', 'are', 'around', 'art', 'as', 'ask', 'asleep', 'ass', 'at', 'ate', 'aw', 'awake', 'awards', 'away', 'awesome', 'aww', 'awww', 'baby', 'back', 'bad', 'band', 'bbq', 'bday', 'be', 'beach', 'beautiful', 'because', 'bed', 'been', 'beer', 'before', 'behind', 'being', 'believe', 'best', 'bet', 'better', 'big', 'bike', 'birthday', 'bit', 'bitch', 'black', 'blip', 'blog', 'blue', 'body', 'boo', 'book', 'books', 'bored', 'boring', 'both', 'bought', 'bout', 'box', 'boy', 'boys', 'break', 'breakfast', 'bring', 'bro', 'broke', 'broken', 'brother', 'brothers', 'btw', 'bus', 'business', 'busy', 'but', 'buy', 'by', 'bye', 'cake', 'call', 'called', 'came', 'can', 'cannot', 'cant', 'car', 'card', 'care', 'case', 'cat', 'catch', 'cause', 'cd', 'chance', 'change', 'channel', 'chat', 'check', 'chicken', 'chocolate', 'church', 'city', 'class', 'clean', 'cleaning', 'close', 'closed', 'club', 'coffee', 'cold', 'college', 'com', 'come', 'comes', 'coming', 'completely', 'computer', 'concert', 'congrats', 'cool', 'cos', 'could', 'couldn', 'country', 'couple', 'course', 'crap', 'crazy', 'cream', 'cry', 'crying', 'cut', 'cute', 'cuz', 'da', 'dad', 'damn', 'dance', 'date', 'daughter', 'david', 'day', 'days', 'ddlovato', 'de', 'dead', 'dear', 'decided', 'definitely', 'did', 'didn', 'didnt', 'die', 'died', 'dinner', 'dm', 'do', 'does', 'doesn', 'doesnt', 'dog', 'doing', 'don', 'done', 'dont', 'down', 'download', 'dream', 'dreams', 'dress', 'drink', 'drinking', 'drive', 'driving', 'drunk', 'dude', 'due', 'during', 'each', 'earlier', 'early', 'easy', 'eat', 'eating', 'either', 'else', 'em', 'email', 'end', 'ended', 'english', 'enjoy', 'enjoyed', 'enjoying', 'enough', 'episode', 'especially', 'even', 'evening', 'ever', 'every', 'everybody', 'everyone', 'everything', 'exactly', 'exam', 'exams', 'except', 'excited', 'exciting', 'eye', 'eyes', 'face', 'facebook', 'fact', 'fail', 'fair', 'fall', 'family', 'fan', 'fans', 'far', 'fast', 'favorite', 'fb', 'feel', 'feeling', 'feels', 'feet', 'fell', 'felt', 'few', 'ff', 'figure', 'final', 'finally', 'finals', 'find', 'fine', 'fingers', 'finish', 'finished', 'fire', 'first', 'fix', 'flight', 'flu', 'fly', 'fm', 'follow', 'followers', 'followfriday', 'following', 'food', 'for', 'forever', 'forget', 'forgot', 'forward', 'found', 'free', 'friday', 'friend', 'friends', 'from', 'front', 'fuck', 'fucking', 'full', 'fun', 'funny', 'game', 'games', 'garden', 'gave', 'gd', 'get', 'gets', 'getting', 'girl', 'girls', 'give', 'glad', 'go', 'god', 'goes', 'goin', 'going', 'gone', 'gonna', 'good', 'goodbye', 'goodnight', 'google', 'got', 'gotta', 'graduation', 'great', 'green', 'gt', 'guess', 'guitar', 'guy', 'guys', 'gym', 'ha', 'had', 'haha', 'hahaha', 'hair', 'half', 'hand', 'hang', 'happen', 'happened', 'happens', 'happy', 'hard', 'has', 'hate', 'hates', 'have', 'haven', 'havent', 'having', 'he', 'head', 'headache', 'headed', 'heading', 'hear', 'heard', 'heart', 'hehe', 'hell', 'hello', 'help', 'her', 'here', 'hey', 'hi', 'high', 'him', 'his', 'history', 'hit', 'hmm', 'holiday', 'home', 'homework', 'hope', 'hopefully', 'hoping', 'horrible', 'hot', 'hotel', 'hour', 'hours', 'house', 'how', 'http', 'hubby', 'hug', 'huge', 'hugs', 'hun', 'hungry', 'hurt', 'hurts', 'ice', 'idea', 'idk', 'if', 'ill', 'im', 'in', 'inside', 'instead', 'interesting', 'internet', 'into', 'iphone', 'ipod', 'is', 'isn', 'isnt', 'it', 'its', 'ive', 'jealous', 'job', 'join', 'jonas', 'jonasbrothers', 'july', 'june', 'jus', 'just', 'keep', 'keeps', 'kid', 'kids', 'kill', 'kind', 'kinda', 'knew', 'know', 'knows', 'la', 'lady', 'lakers', 'lame', 'laptop', 'last', 'late', 'later', 'laugh', 'lazy', 'learn', 'learning', 'least', 'leave', 'leaving', 'left', 'less', 'let', 'lets', 'life', 'like', 'liked', 'lil', 'line', 'link', 'list', 'listen', 'listening', 'little', 'live', 'living', 'll', 'lmao', 'lol', 'london', 'lonely', 'long', 'longer', 'look', 'looked', 'looking', 'looks', 'lost', 'lot', 'lots', 'love', 'loved', 'lovely', 'loves', 'loving', 'lt', 'luck', 'lucky', 'lunch', 'luv', 'ly', 'ma', 'mac', 'mad', 'made', 'mail', 'major', 'make', 'makes', 'making', 'man', 'many', 'maths', 'matter', 'may', 'maybe', 'mcfly', 'me', 'mean', 'means', 'meant', 'meet', 'meeting', 'message', 'met', 'might', 'miley', 'mileycyrus', 'mind', 'mine', 'minute', 'minutes', 'miss', 'missed', 'missing', 'mom', 'moment', 'monday', 'money', 'month', 'months', 'mood', 'moon', 'more', 'morning', 'most', 'mother', 'mouth', 'move', 'movie', 'movies', 'moving', 'mr', 'mtv', 'much', 'mum', 'music', 'must', 'my', 'myloc', 'myself', 'myspace', 'name', 'nap', 'near', 'need', 'needed', 'needs', 'never', 'new', 'news', 'next', 'nice', 'night', 'nights', 'nite', 'no', 'nope', 'not', 'nothing', 'now', 'number', 'of', 'off', 'office', 'oh', 'ohh', 'ok', 'okay', 'old', 'omg', 'on', 'once', 'one', 'ones', 'online', 'only', 'open', 'or', 'other', 'ouch', 'our', 'out', 'outside', 'over', 'own', 'packing', 'page', 'pain', 'paper', 'parents', 'park', 'part', 'party', 'pass', 'past', 'pay', 'peace', 'people', 'perfect', 'person', 'phone', 'photo', 'photos', 'pic', 'pick', 'pics', 'picture', 'pictures', 'pink', 'pizza', 'place', 'plan', 'plans', 'play', 'played', 'playing', 'please', 'pls', 'plurk', 'plus', 'point', 'pool', 'poor', 'post', 'posted', 'power', 'ppl', 'pretty', 'probably', 'problem', 'profile', 'project', 'proud', 'put', 'quite', 'quot', 'radio', 'rain', 'raining', 'rainy', 'random', 'rather', 're', 'read', 'reading', 'ready', 'real', 'realized', 'really', 'reason', 'red', 'relaxing', 'remember', 'reply', 'rest', 'revision', 'ride', 'right', 'rip', 'road', 'rock', 'room', 'run', 'running', 'sad', 'sadly', 'safe', 'said', 'same', 'sat', 'saturday', 'save', 'saw', 'say', 'saying', 'says', 'scared', 'scary', 'school', 'season', 'second', 'see', 'seeing', 'seem', 'seems', 'seen', 'send', 'sent', 'seriously', 'set', 'shall', 'shame', 'share', 'she', 'shirt', 'shit', 'shoes', 'shop', 'shopping', 'short', 'should', 'show', 'shower', 'shows', 'sick', 'side', 'sigh', 'sign', 'silly', 'sims', 'since', 'singing', 'sister', 'site', 'sitting', 'sleep', 'sleeping', 'sleepy', 'slept', 'slow', 'small', 'smile', 'so', 'some', 'someone', 'something', 'sometimes', 'son', 'song', 'songs', 'soo', 'soon', 'sooo', 'soooo', 'sore', 'sorry', 'sound', 'sounds', 'special', 'spend', 'spending', 'spent', 'star', 'start', 'started', 'starting', 'starts', 'stay', 'still', 'stomach', 'stop', 'store', 'story', 'straight', 'stuck', 'study', 'studying', 'stuff', 'stupid', 'such', 'suck', 'sucks', 'summer', 'sun', 'sunday', 'sunny', 'sunshine', 'super', 'support', 'supposed', 'sure', 'sweet', 'take', 'takes', 'taking', 'talk', 'talking', 'taylor', 'tea', 'team', 'tell', 'test', 'text', 'than', 'thank', 'thanks', 'that', 'thats', 'the', 'their', 'them', 'then', 'there', 'these', 'they', 'thing', 'things', 'think', 'thinking', 'thinks', 'this', 'tho', 'those', 'though', 'thought', 'three', 'throat', 'through', 'thru', 'thursday', 'thx', 'tickets', 'til', 'till', 'time', 'times', 'tinyurl', 'tired', 'to', 'today', 'together', 'told', 'tom', 'tommcfly', 'tomorrow', 'tonight', 'too', 'took', 'top', 'totally', 'tour', 'town', 'traffic', 'train', 'tried', 'trip', 'true', 'try', 'trying', 'tuesday', 'turn', 'tv', 'tweet', 'tweeting', 'tweets', 'twilight', 'twitpic', 'twitter', 'two', 'ugh', 'uk', 'under', 'understand', 'unfortunately', 'until', 'up', 'update', 'updates', 'upset', 'ur', 'us', 'use', 'used', 'using', 'vacation', 've', 'vegas', 'version', 'very', 'via', 'video', 'visit', 'voice', 'wait', 'waiting', 'wake', 'walk', 'wanna', 'want', 'wanted', 'wants', 'warm', 'was', 'wasn', 'watch', 'watched', 'watching', 'water', 'way', 'we', 'wear', 'weather', 'website', 'wedding', 'wednesday', 'week', 'weekend', 'weeks', 'weird', 'welcome', 'well', 'went', 'were', 'what', 'whats', 'when', 'where', 'which', 'while', 'white', 'who', 'whole', 'why', 'wife', 'will', 'win', 'wine', 'wish', 'wishes', 'wishing', 'wit', 'with', 'without', 'woke', 'won', 'wonder', 'wonderful', 'wondering', 'wont', 'woo', 'word', 'words', 'work', 'worked', 'working', 'works', 'world', 'worried', 'worry', 'worse', 'worst', 'worth', 'would', 'wouldn', 'wow', 'write', 'writing', 'wrong', 'wtf', 'www', 'xd', 'xoxo', 'xx', 'xxx', 'ya', 'yay', 'yea', 'yeah', 'year', 'years', 'yep', 'yes', 'yesterday', 'yet', 'yo', 'you', 'young', 'your', 'yourself', 'youtube', 'yum', 'yup']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>1st</th>\n",
       "      <th>20</th>\n",
       "      <th>2day</th>\n",
       "      <th>2nd</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yum</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10  100   11   12   15  1st   20  2day  2nd   30  ...  yesterday  yet  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...        0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...        0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...        0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...        0.0  0.0   \n",
       "\n",
       "    yo  you  young  your  yourself  youtube  yum  yup  \n",
       "0  0.0  0.0    0.0   0.0       0.0      0.0  0.0  0.0  \n",
       "1  0.0  0.0    0.0   0.0       0.0      0.0  0.0  0.0  \n",
       "2  0.0  0.0    0.0   0.0       0.0      0.0  0.0  0.0  \n",
       "3  0.0  0.0    0.0   0.0       0.0      0.0  0.0  0.0  \n",
       "\n",
       "[4 rows x 1000 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put it through the vectoriser\n",
    "\n",
    "# transform, not fit_transform, because we already learned all our words\n",
    "unknown_vectors = vectorizer.transform(unknown.content)\n",
    "unknown_words_df = pd.DataFrame(unknown_vectors.toarray(), columns=vectorizer.get_feature_names())\n",
    "unknown_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 87.9 ms, sys: 3.47 ms, total: 91.4 ms\n",
      "Wall time: 103 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Predict using all our models. \n",
    "\n",
    "# Logistic Regression predictions + probabilities\n",
    "unknown['pred_logreg'] = logreg.predict(unknown_words_df)\n",
    "unknown['pred_logreg_proba'] = logreg.predict_proba(unknown_words_df)[:,1]\n",
    "\n",
    "# Bayes predictions + probabilities\n",
    "unknown['pred_bayes'] = bayes.predict(unknown_words_df)\n",
    "unknown['pred_bayes_proba'] = bayes.predict_proba(unknown_words_df)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>pred_logreg</th>\n",
       "      <th>pred_logreg_proba</th>\n",
       "      <th>pred_bayes</th>\n",
       "      <th>pred_bayes_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I dont know what to think about it</td>\n",
       "      <td>0</td>\n",
       "      <td>0.326024</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That was fucking awesome dawg!</td>\n",
       "      <td>1</td>\n",
       "      <td>0.685195</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goddamn what a miracle!</td>\n",
       "      <td>1</td>\n",
       "      <td>0.509478</td>\n",
       "      <td>1</td>\n",
       "      <td>0.507385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Son of a bitch!</td>\n",
       "      <td>1</td>\n",
       "      <td>0.509502</td>\n",
       "      <td>0</td>\n",
       "      <td>0.404694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              content  pred_logreg  pred_logreg_proba  \\\n",
       "0  I dont know what to think about it            0           0.326024   \n",
       "1      That was fucking awesome dawg!            1           0.685195   \n",
       "2             Goddamn what a miracle!            1           0.509478   \n",
       "3                     Son of a bitch!            1           0.509502   \n",
       "\n",
       "   pred_bayes  pred_bayes_proba  \n",
       "0           0          0.420156  \n",
       "1           1          0.545361  \n",
       "2           1          0.507385  \n",
       "3           0          0.404694  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
